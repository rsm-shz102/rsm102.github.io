[
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "My Blogs",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nShuyang Zhang\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Analysis of Cars\n\n\n\n\n\n\nYour Name\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blogs/blog1/hw1_questions.html",
    "href": "blogs/blog1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment was carefully designed to test whether offering a matching grant increases the likelihood and amount of donations. Over 50,000 individuals who had previously donated to a liberal nonprofit organization were randomly assigned into different treatment groups. The treatments varied along three dimensions: (1) the match ratio ($1:$1, $2:$1, or $3:$1), (2) the maximum match amount ($25,000, $50,000, $100,000, or unstated), and (3) the suggested donation amount (equal to, 1.25x, or 1.5x the donor’s previous highest gift).\nEach letter was identical except for the paragraph describing the match, and the response card formatting. The study aimed to test if higher match rates would induce greater giving and whether these effects varied across political geography or donor history. The results offer key insights for nonprofits on designing cost-effective fundraising strategies.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blogs/blog1/hw1_questions.html#introduction",
    "href": "blogs/blog1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment was carefully designed to test whether offering a matching grant increases the likelihood and amount of donations. Over 50,000 individuals who had previously donated to a liberal nonprofit organization were randomly assigned into different treatment groups. The treatments varied along three dimensions: (1) the match ratio ($1:$1, $2:$1, or $3:$1), (2) the maximum match amount ($25,000, $50,000, $100,000, or unstated), and (3) the suggested donation amount (equal to, 1.25x, or 1.5x the donor’s previous highest gift).\nEach letter was identical except for the paragraph describing the match, and the response card formatting. The study aimed to test if higher match rates would induce greater giving and whether these effects varied across political geography or donor history. The results offer key insights for nonprofits on designing cost-effective fundraising strategies.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blogs/blog1/hw1_questions.html#data",
    "href": "blogs/blog1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf.shape\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another. \nAs an ad hoc test of the randomization mechanism, I conduct a set of tests to compare the treatment and control groups on selected pre-treatment variables. The variables I test are: - mrm2: Months since last donation\n- female: Indicator for female donors\n- freq: Number of prior donations\n- amountchange: Change in amount given\n- hpa: Highest previous donation\n- years: Number of years since initial donation\n- couple: Indicator for couple households\nThese are not outcome variables but may affect donation behavior, so we test whether these variables differ significantly between groups.\n\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\nimport pandas as pd\n\n# --- T-tests ---\nt_mrm2 = ttest_ind(df[df['treatment'] == 1]['mrm2'],\n                   df[df['treatment'] == 0]['mrm2'],\n                   nan_policy='omit')\nt_female = ttest_ind(df[df['treatment'] == 1]['female'],\n                     df[df['treatment'] == 0]['female'],\n                     nan_policy='omit')\nt_freq = ttest_ind(df[df['treatment'] == 1]['freq'],\n                   df[df['treatment'] == 0]['freq'],\n                   nan_policy='omit')\nt_amtchg = ttest_ind(df[df['treatment'] == 1]['amountchange'],\n                     df[df['treatment'] == 0]['amountchange'],\n                     nan_policy='omit')\nt_hpa = ttest_ind(df[df['treatment'] == 1]['hpa'],\n                  df[df['treatment'] == 0]['hpa'],\n                  nan_policy='omit')\n\nt_years = ttest_ind(df[df['treatment'] == 1]['years'],\n                    df[df['treatment'] == 0]['years'],\n                    nan_policy='omit')\n\nt_couple = ttest_ind(df[df['treatment'] == 1]['couple'],\n                     df[df['treatment'] == 0]['couple'],\n                     nan_policy='omit')\n\n# --- OLS regressions ---\nols_mrm2 = smf.ols('mrm2 ~ treatment', data=df).fit()\nols_female = smf.ols('female ~ treatment', data=df).fit()\nols_freq = smf.ols('freq ~ treatment', data=df).fit()\nols_amtchg = smf.ols('amountchange ~ treatment', data=df).fit()\nols_hpa = smf.ols(\"hpa ~ treatment\", data=df).fit()\nols_years = smf.ols(\"years ~ treatment\", data=df).fit()\nols_couple = smf.ols(\"couple ~ treatment\", data=df).fit()\n# --- Assemble into a DataFrame for table ---\nbalance_table = pd.DataFrame({\n    'Variable': ['mrm2', 'female', 'freq', 'amountchange', 'hpa', 'years', 'couple'],\n    'T-stat': [\n        round(t_mrm2.statistic, 4),\n        round(t_female.statistic, 4),\n        round(t_freq.statistic, 4),\n        round(t_amtchg.statistic, 4),\n        round(t_hpa.statistic, 4),\n        round(t_years.statistic, 4),\n        round(t_couple.statistic, 4)\n    ],\n    'T p-value': [\n        round(t_mrm2.pvalue, 4),\n        round(t_female.pvalue, 4),\n        round(t_freq.pvalue, 4),\n        round(t_amtchg.pvalue, 4),\n        round(t_hpa.pvalue, 4),\n        round(t_years.pvalue, 4),\n        round(t_couple.pvalue, 4)\n    ],\n    'OLS coef (treatment)': [\n        round(ols_mrm2.params['treatment'], 4),\n        round(ols_female.params['treatment'], 4),\n        round(ols_freq.params['treatment'], 4),\n        round(ols_amtchg.params['treatment'], 4),\n        round(ols_hpa.params['treatment'], 4),\n        round(ols_years.params['treatment'], 4),\n        round(ols_couple.params['treatment'], 4)\n    ],\n    'OLS p-value': [\n        round(ols_mrm2.pvalues['treatment'], 4),\n        round(ols_female.pvalues['treatment'], 4),\n        round(ols_freq.pvalues['treatment'], 4),\n        round(ols_amtchg.pvalues['treatment'], 4),\n        round(ols_hpa.pvalues['treatment'], 4),\n        round(ols_years.pvalues['treatment'], 4),\n        round(ols_couple.pvalues['treatment'], 4)\n    ]\n})\n\nbalance_table\n\n\n\n\n\n\n\n\nVariable\nT-stat\nT p-value\nOLS coef (treatment)\nOLS p-value\n\n\n\n\n0\nmrm2\n0.1195\n0.9049\n0.0137\n0.9049\n\n\n1\nfemale\n-1.7584\n0.0787\n-0.0075\n0.0787\n\n\n2\nfreq\n-0.1109\n0.9117\n-0.0120\n0.9117\n\n\n3\namountchange\n0.5270\n0.5982\n6.3306\n0.5982\n\n\n4\nhpa\n0.9441\n0.3451\n0.6371\n0.3451\n\n\n5\nyears\n-1.1030\n0.2700\n-0.0575\n0.2700\n\n\n6\ncouple\n-0.5838\n0.5594\n-0.0016\n0.5594\n\n\n\n\n\n\n\nThe t-tests and regressions show that none of the selected variables are significantly different between the treatment and control groups at the 5% level (all p-values &gt; 0.05). This suggests that the randomization was successful in creating statistically balanced groups.\nThis step is crucial to establish causal inference credibility, and aligns with the paper’s Table 1, which also shows nearly identical summary statistics across groups. Our results replicate and reinforce their findings."
  },
  {
    "objectID": "blogs/blog1/hw1_questions.html#experimental-results",
    "href": "blogs/blog1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation. \n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndonation_rate = df.groupby('treatment')['gave'].mean().reset_index()\ndonation_rate['Group'] = donation_rate['treatment'].map({0: 'Control', 1: 'Treatment'})\ndonation_rate['gave'] = donation_rate['gave'] * 100 \n\n\nax = sns.barplot(data=donation_rate, x='Group', y='gave')\nplt.ylabel('Proportion who donated (%)')\nplt.title('Donation Rate by Group')\nplt.ylim(0, 5)\n\nfor i, row in donation_rate.iterrows():\n    ax.text(i, row['gave'] + 0.1, f\"{row['gave']:.1f}%\", ha='center', va='bottom')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\nimport pandas as pd\n\n# T-test on binary outcome (gave)\nt_gave = ttest_ind(df[df['treatment'] == 1]['gave'],\n                   df[df['treatment'] == 0]['gave'],\n                   nan_policy='omit')\n\n# OLS regression\nols_gave = smf.ols(\"gave ~ treatment\", data=df).fit()\n\n# Create a table for results\nresults_table = pd.DataFrame({\n    'Method': ['T-test', 'OLS Regression'],\n    'Statistic': [round(t_gave.statistic, 4), round(ols_gave.params['treatment'], 4)],\n    'P-value': [round(t_gave.pvalue, 4), round(ols_gave.pvalues['treatment'], 4)]\n})\n\nresults_table\n\n\n\n\n\n\n\n\nMethod\nStatistic\nP-value\n\n\n\n\n0\nT-test\n3.1014\n0.0019\n\n\n1\nOLS Regression\n0.0042\n0.0019\n\n\n\n\n\n\n\nBoth the t-test and OLS regression yield consistent results, showing a statistically significant difference in donation rates between the treatment and control groups. The p-value in both cases is 0.002, indicating strong evidence against the null hypothesis of no difference.\nThe estimated effect size from the OLS model is 0.004, meaning that the treatment group was 0.4 percentage points more likely to donate than the control group. While this may seem small in absolute terms, it is statistically meaningful given the large sample size.\nThis suggests that offering a matching grant—even without changing the ratio—has a measurable impact on charitable behavior. Individuals respond to the presence of a match by becoming more likely to donate, reinforcing the idea that perceived leverage or validation may encourage prosocial behavior.\n\n\nimport statsmodels.formula.api as smf\n\n# Probit model with interactions — replicate Table 3 Column 1\nprobit_formula = (\n    \"gave ~ treatment + \"\n    \"treatment:ratio2 + treatment:ratio3 + \"\n    \"treatment:size25 + treatment:size50 + treatment:size100 + \"\n    \"treatment:ask2 + treatment:ask3\"\n)\n\nprobit_model = smf.probit(probit_formula, data=df).fit()\ncoef_table = pd.DataFrame({\n    'Variable': probit_model.params.index,\n    'Coef': probit_model.params.values.round(4),\n    'StdErr': probit_model.bse.round(4),\n    'P&gt;|z|': probit_model.pvalues.round(4)\n})\n\ncoef_table\n\nOptimization terminated successfully.\n         Current function value: 0.100276\n         Iterations 7\n\n\n\n\n\n\n\n\n\nVariable\nCoef\nStdErr\nP&gt;|z|\n\n\n\n\nIntercept\nIntercept\n-2.1001\n0.0233\n0.0000\n\n\ntreatment\ntreatment\n0.0656\n0.0462\n0.1558\n\n\ntreatment:ratio2\ntreatment:ratio2\n0.0370\n0.0377\n0.3266\n\n\ntreatment:ratio3\ntreatment:ratio3\n0.0398\n0.0377\n0.2914\n\n\ntreatment:size25\ntreatment:size25\n-0.0129\n0.0434\n0.7673\n\n\ntreatment:size50\ntreatment:size50\n0.0052\n0.0431\n0.9040\n\n\ntreatment:size100\ntreatment:size100\n-0.0010\n0.0432\n0.9813\n\n\ntreatment:ask2\ntreatment:ask2\n0.0198\n0.0059\n0.0008\n\n\ntreatment:ask3\ntreatment:ask3\n-0.0164\n0.0049\n0.0009\n\n\n\n\n\n\n\nThe Probit regression model successfully replicates the specification used in Table 3, Column 1 of the original paper. While the magnitude of the coefficients is slightly different due to estimation of latent z-scores (as opposed to marginal effects reported in the paper), the signs and patterns of significance are broadly consistent.\nSpecifically: - The treatment effect is positive but not statistically significant in both models. - The interaction terms for match ratio and match size are not significant. - The treatment * ask2 and treatment * ask3 interactions are statistically significant at the 1% level, consistent with the original finding that suggested donation amounts influence donor responsiveness.\nTherefore, this analysis supports the robustness of the original findings.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate. \n\nfrom scipy.stats import ttest_ind\nimport pandas as pd\n\n# Filter treatment group by different match ratios\nratio1 = df[(df['ratio'] == 1) & (df['treatment'] == 1)]\nratio2 = df[(df['ratio2'] == 1) & (df['treatment'] == 1)]\nratio3 = df[(df['ratio3'] == 1) & (df['treatment'] == 1)]\n\n# Perform t-tests\nt_ratio2 = ttest_ind(ratio2['gave'], ratio1['gave'], nan_policy='omit')\nt_ratio3 = ttest_ind(ratio3['gave'], ratio1['gave'], nan_policy='omit')\n\n# Create a table for results\nt_test_results = pd.DataFrame({\n    'Comparison': ['2:1 vs 1:1', '3:1 vs 1:1'],\n    'T-statistic': [round(t_ratio2.statistic, 4), round(t_ratio3.statistic, 4)],\n    'P-value': [round(t_ratio2.pvalue, 4), round(t_ratio3.pvalue, 4)]\n})\n\nt_test_results\n\n\n\n\n\n\n\n\nComparison\nT-statistic\nP-value\n\n\n\n\n0\n2:1 vs 1:1\n0.965\n0.3345\n\n\n1\n3:1 vs 1:1\n1.015\n0.3101\n\n\n\n\n\n\n\nThe results from the t-tests show that the differences in donation rates between 1:1, 2:1, and 3:1 match ratios are not statistically significant. This supports the original paper’s statement on page 8 that higher match ratios do not systematically lead to greater donation likelihood. Our findings are consistent with the paper’s Figure 2a and the authors’ interpretation. \n\nimport statsmodels.formula.api as smf\nfrom scipy.stats import ttest_ind\nimport pandas as pd\n\n# Regression: gave ~ ratio2 + ratio3 (1:1 as the baseline)\nols_ratio = smf.ols(\"gave ~ ratio2 + ratio3\", data=df[df['treatment'] == 1]).fit()\n\n# T-tests: 2:1 vs 1:1, 3:1 vs 1:1, 3:1 vs 2:1\nt_ratio2 = ttest_ind(\n    df[(df['ratio2'] == 1) & (df['treatment'] == 1)]['gave'],\n    df[(df['ratio'] == 1) & (df['treatment'] == 1)]['gave'],\n    nan_policy='omit'\n)\n\nt_ratio3 = ttest_ind(\n    df[(df['ratio3'] == 1) & (df['treatment'] == 1)]['gave'],\n    df[(df['ratio'] == 1) & (df['treatment'] == 1)]['gave'],\n    nan_policy='omit'\n)\n\nt_3v2 = ttest_ind(\n    df[(df['ratio3'] == 1) & (df['treatment'] == 1)]['gave'],\n    df[(df['ratio2'] == 1) & (df['treatment'] == 1)]['gave'],\n    nan_policy='omit'\n)\n\n# Output OLS regression summary\nols_result_table = pd.DataFrame({\n    'Variable': ols_ratio.params.index,\n    'Coefficient': ols_ratio.params.round(4),\n    'Std. Error': ols_ratio.bse.round(4),\n    'P-value': ols_ratio.pvalues.round(4)\n})\nprint(ols_result_table)\n# Organize all t-test results into a table\nt_test_table = pd.DataFrame({\n    'Comparison': ['2:1 vs 1:1', '3:1 vs 1:1', '3:1 vs 2:1'],\n    'T-statistic': [\n        round(t_ratio2.statistic, 4),\n        round(t_ratio3.statistic, 4),\n        round(t_3v2.statistic, 4)\n    ],\n    'P-value': [\n        round(t_ratio2.pvalue, 4),\n        round(t_ratio3.pvalue, 4),\n        round(t_3v2.pvalue, 4)\n    ]\n})\n\nt_test_table\n\n            Variable  Coefficient  Std. Error  P-value\nIntercept  Intercept       0.0207      0.0014   0.0000\nratio2        ratio2       0.0019      0.0020   0.3383\nratio3        ratio3       0.0020      0.0020   0.3133\n\n\n\n\n\n\n\n\n\nComparison\nT-statistic\nP-value\n\n\n\n\n0\n2:1 vs 1:1\n0.9650\n0.3345\n\n\n1\n3:1 vs 1:1\n1.0150\n0.3101\n\n\n2\n3:1 vs 2:1\n0.0501\n0.9600\n\n\n\n\n\n\n\nThe regression and t-tests show that neither the 2:1 nor 3:1 match ratios lead to statistically significant increases in donation rates compared to the 1:1 baseline. The coefficient estimates are small and not significant, and the t-tests confirm no meaningful differences.\nThis finding is consistent with the original paper (Karlan & List, 2007), which states on page 8 that “we do not find systematic patterns” related to match ratio. It suggests that while the presence of a match increases donations, higher match ratios do not provide additional gains. \n\n# Extract coefficients\nb_2v1 = ols_ratio.params['ratio2']\nb_3v1 = ols_ratio.params['ratio3']\n\n# Create a table for the differences\nresponse_rate_diff_table = pd.DataFrame({\n    'Comparison': ['2:1 vs 1:1', '3:1 vs 1:1'],\n    'Estimated Difference': [round(b_2v1, 4), round(b_3v1, 4)]\n})\n\nresponse_rate_diff_table\n\n\n\n\n\n\n\n\nComparison\nEstimated Difference\n\n\n\n\n0\n2:1 vs 1:1\n0.0019\n\n\n1\n3:1 vs 1:1\n0.0020\n\n\n\n\n\n\n\nUsing the fitted coefficients from the OLS regression, we find that: - The 2:1 match ratio group donated at a rate approximately 0.0019 higher than the 1:1 group. - The 3:1 match ratio group donated at a rate approximately 0.0020 higher than the 1:1 group.\nThese differences are very small and, as shown earlier, not statistically significant. We conclude that while matching donations increase giving relative to no match, increasing the match ratio from 1:1 to 2:1 or 3:1 provides little to no additional benefit. This supports the authors’ conclusion that “figures suggest” higher match ratios do not systematically increase donation behavior.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution. \n\n# OLS regression on full sample\nols_amount_all = smf.ols(\"amount ~ treatment\", data=df).fit()\n\n# T-test (optional)\nfrom scipy.stats import ttest_ind\nt_amount_all = ttest_ind(\n    df[df['treatment'] == 1]['amount'],\n    df[df['treatment'] == 0]['amount'],\n    nan_policy='omit'\n)\n\n# Show results\namount_all_table = pd.DataFrame({\n    'Model': ['OLS: all'],\n    'Coefficient': [round(ols_amount_all.params['treatment'], 4)],\n    'P-value': [round(ols_amount_all.pvalues['treatment'], 4)]\n})\n\namount_all_table\n\n\n\n\n\n\n\n\nModel\nCoefficient\nP-value\n\n\n\n\n0\nOLS: all\n0.1536\n0.0628\n\n\n\n\n\n\n\nThe OLS regression on the full sample shows that the treatment group gave on average $0.15 more than the control group. The p-value is approximately 0.063, indicating marginal significance at the 10% level. This suggests that matching offers may slightly increase the average donation amount when including everyone, even non-donors.\nHowever, since many people donate $0, this increase is driven largely by the increase in the probability of giving, not necessarily the amount conditional on giving. \n\n# OLS for donors only\nols_amount_givers = smf.ols(\"amount ~ treatment\", data=df[df['gave'] == 1]).fit()\n\n# Summary table\namount_givers_table = pd.DataFrame({\n    'Model': ['OLS: donors only'],\n    'Coefficient': [round(ols_amount_givers.params['treatment'], 4)],\n    'P-value': [round(ols_amount_givers.pvalues['treatment'], 4)]\n})\n\namount_givers_table\n\n\n\n\n\n\n\n\nModel\nCoefficient\nP-value\n\n\n\n\n0\nOLS: donors only\n-1.6684\n0.5615\n\n\n\n\n\n\n\nAmong those who donated, the treatment group gave on average $1.67 less than the control group, though this difference is not statistically significant (p = 0.56). This suggests no meaningful treatment effect on the donation amount once someone decides to give.\nImportantly, this estimate does not have a causal interpretation. By restricting the sample to only those who donated, we lose the benefit of random assignment. The two groups may differ in unobservable ways, and the treatment coefficient may be biased due to selection. Therefore, this regression is descriptive but not causal. \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Filter to only people who donated\ndonors = df[df['gave'] == 1]\n\n# Split into treatment and control\ntreatment_group = donors[donors['treatment'] == 1]\ncontrol_group = donors[donors['treatment'] == 0]\n\n# Calculate means\nmean_treatment = treatment_group['amount'].mean()\nmean_control = control_group['amount'].mean()\n\n# Plot\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# Control group plot\nsns.histplot(control_group['amount'], bins=30, ax=axes[0])\naxes[0].axvline(mean_control, color='red', linestyle='--', label=f'Mean: {mean_control:.2f}')\naxes[0].set_title('Control Group')\naxes[0].set_xlabel('Donation Amount')\naxes[0].legend()\n\n# Treatment group plot\nsns.histplot(treatment_group['amount'], bins=30, ax=axes[1], color='lightgreen')\naxes[1].axvline(mean_treatment, color='red', linestyle='--', label=f'Mean: {mean_treatment:.2f}')\naxes[1].set_title('Treatment Group')\naxes[1].set_xlabel('Donation Amount')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe histograms above compare the distribution of donation amounts between the treatment and control groups, including only individuals who made a donation. Each red dashed line marks the average donation within that group.\nThe distribution shapes are broadly similar across groups, with both being right-skewed due to a few large donations. The treatment group appears to have a slightly lower average donation amount ($43.87) compared to the control group ($45.54), consistent with the regression results in the previous section.\nThis visualization supports the earlier finding that while matching offers may increase the likelihood of giving, they do not significantly affect the amount donated among those who give."
  },
  {
    "objectID": "blogs/blog1/hw1_questions.html#simulation-experiment",
    "href": "blogs/blog1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Simulate 10,000 samples from each group\nn = 10000\ncontrol_draws = np.random.binomial(1, 0.018, n)\ntreatment_draws = np.random.binomial(1, 0.022, n)\n\n# Compute difference at each position\ndifferences = treatment_draws - control_draws\n\n# Compute cumulative average of differences\ncumulative_avg = np.cumsum(differences) / np.arange(1, n+1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label=\"Cumulative Avg Difference\")\nplt.axhline(y=0.004, color='red', linestyle='--', label='True Difference (0.004)')\nplt.title(\"Law of Large Numbers: Simulated Cumulative Average of Treatment-Control\")\nplt.xlabel(\"Number of Simulated Pairs\")\nplt.ylabel(\"Average Difference\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThis plot illustrates the Law of Large Numbers (LLN) through a simulation. We simulate 10,000 Bernoulli draws from a control group with donation probability 0.018 and a treatment group with probability 0.022. At each step, we calculate the difference between treatment and control, and track the cumulative average.\nAs seen in the plot, the average difference fluctuates significantly at the beginning due to randomness in small samples. However, as the number of simulated observations increases, the cumulative average stabilizes around the true population difference of 0.004 (red dashed line). This demonstrates how, with large samples, the sample mean converges to the true mean difference — a key concept behind t-tests and statistical inference.\n\n\nCentral Limit Theorem\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set parameters\np_control = 0.018\np_treatment = 0.022\nn_sims = 1000\nsample_sizes = [50, 200, 500, 1000]\n\n# Set random seed\nnp.random.seed(42)\n\n# Plot\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    avg_diffs = []\n    for _ in range(n_sims):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diff = np.mean(treatment_sample) - np.mean(control_sample)\n        avg_diffs.append(diff)\n\n    sns.histplot(avg_diffs, bins=30, ax=axes[i], kde=True)\n    axes[i].axvline(x=0, color='red', linestyle='--', label='Zero')\n    axes[i].axvline(x=0.004, color='green', linestyle='--', label='True Diff')\n    axes[i].set_title(f\"Sample size = {n}\")\n    axes[i].legend()\n\nplt.suptitle(\"Central Limit Theorem: Distribution of Mean Differences\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe four histograms above illustrate the Central Limit Theorem using simulated donation decisions. For each sample size (50, 200, 500, 1000), we simulate 1,000 differences in group means between a control group (p=0.018) and a treatment group (p=0.022).\nAs the sample size increases: - The distribution of mean differences becomes more bell-shaped (normal-like) - The spread (variance) becomes smaller - The mean of the distribution centers closer to the true difference (0.004)\nWe also see that zero is not in the middle of the distribution, especially as n gets larger. This suggests that the difference between groups becomes detectable at large sample sizes, which is the intuition behind statistical significance in t-tests."
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Let’s investigate the relationship between fuel efficiency (mpg) and engine displacement (disp) from the mtcars dataset. Those variables have a correlation of r cor(mtcars$mpg, mtcars$disp) |&gt; format(digits=2).\n\n\nHere is a plot:"
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Here is a plot:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Shuyang Zhang",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  }
]